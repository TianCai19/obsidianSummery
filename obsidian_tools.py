# File 1: obsidian_tools.py
import os
import re
import signal
import time
from typing import Set
from openai import OpenAI, APIError
from frontmatter import Frontmatter

class SummaryProcessor:
    def __init__(self, client: OpenAI):
        self.client = client
        self.interrupted = False
        self.stats = {
            "total_files": 0,
            "processed_files": 0,
            "skipped_files": 0,
            "total_tokens": 0,
            "start_time": time.time()
        }
        signal.signal(signal.SIGINT, self.handle_interrupt)

    def handle_interrupt(self, signum, frame):
        """å¤„ç†ä¸­æ–­ä¿¡å·"""
        self.interrupted = True
        print("\næ£€æµ‹åˆ°ä¸­æ–­ï¼Œæ­£åœ¨ä¿å­˜å½“å‰è¿›åº¦...")

    def get_processed_links(self, output_path: str) -> Set[str]:
        """è·å–å·²å¤„ç†çš„æ–‡æ¡£é“¾æ¥"""
        processed = set()
        if os.path.exists(output_path):
            with open(output_path, "r", encoding="utf-8") as f:
                content = f.read()
                matches = re.findall(r"\[\[(.*?)\]\]", content)
                processed = set(matches)
        return processed

    def process_content(self, raw_content: str) -> str:
        """é¢„å¤„ç†Markdownå†…å®¹"""
        try:
            post = Frontmatter.reads(raw_content)
            return post.content
        except:
            return raw_content

    def generate_summary(self, content: str) -> (str, int):
        """ç”Ÿæˆæ‘˜è¦å¹¶è¿”å›tokenä½¿ç”¨é‡"""
        try:
            response = self.client.chat.completions.create(
                model="deepseek-chat",
                messages=[
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å†…å®¹æ‘˜è¦åŠ©ç†ï¼Œç”¨3å¥æµç•…çš„ä¸­æ–‡æ€»ç»“ä»¥ä¸‹å†…å®¹çš„æ ¸å¿ƒè§‚ç‚¹ï¼Œä¿æŒä¸“ä¸šä¸”æ˜“äºç†è§£"
                    },
                    {
                        "role": "user", 
                        "content": f"{content[:3500]}"
                    }
                ],
                temperature=0.3,
                max_tokens=256
            )
            
            usage = response.usage.total_tokens
            return response.choices[0].message.content.strip(), usage
            
        except APIError as e:
            print(f"\n[APIé”™è¯¯] çŠ¶æ€ç ï¼š{e.status_code} | é”™è¯¯ä¿¡æ¯ï¼š{e.message}")
        except Exception as e:
            print(f"\n[ç³»ç»Ÿé”™è¯¯] {str(e)}")
        
        return "", 0

    def print_progress(self):
        """æ˜¾ç¤ºå®æ—¶è¿›åº¦"""
        elapsed = time.time() - self.stats["start_time"]
        processed = self.stats["processed_files"]
        total = self.stats["total_files"]
        
        progress = processed / total if total > 0 else 0
        eta = (total - processed) * elapsed / processed if processed > 0 else 0
        
        print(f"\rğŸš€ è¿›åº¦: {processed}/{total} ({progress:.1%}) | "
              f"â³ ç”¨æ—¶: {elapsed:.1f}s | "
              f"ğŸ“Š Token: {self.stats['total_tokens']} | "
              f"ğŸ•’ å‰©ä½™: {eta:.1f}s", end="")

    def init_output_file(self, output_path: str):
        """åˆå§‹åŒ–è¾“å‡ºæ–‡ä»¶"""
        if not os.path.exists(output_path):
            with open(output_path, "w", encoding="utf-8") as f:
                f.write("# Obsidian æ–‡æ¡£æ‘˜è¦æ±‡æ€»\n\n")
                f.write("> è‡ªåŠ¨ç”Ÿæˆäº {}\n\n".format(time.strftime("%Y-%m-%d %H:%M")))
        else:
            # æ£€æŸ¥æ–‡ä»¶å¤´æ˜¯å¦å®Œæ•´
            with open(output_path, "r+", encoding="utf-8") as f:
                content = f.read()
                if not content.startswith("# Obsidian æ–‡æ¡£æ‘˜è¦æ±‡æ€»"):
                    f.seek(0, 0)
                    f.write("# Obsidian æ–‡æ¡£æ‘˜è¦æ±‡æ€»\n\n> è‡ªåŠ¨ç”Ÿæˆäº {}\n\n".format(time.strftime("%Y-%m-%d %H:%M")) + content)

    def process_vault(self, vault_path: str, output_file: str) -> None:
        """å¤„ç†æ•´ä¸ªçŸ¥è¯†åº“"""
        output_path = os.path.join(vault_path, output_file)
        processed_links = self.get_processed_links(output_path)
        self.init_output_file(output_path)
        
        # ç»Ÿè®¡æ€»æ–‡ä»¶æ•°
        self.stats["total_files"] = sum(
            len(files) 
            for root, _, files in os.walk(vault_path) 
            if not any(x in root for x in ["templates", ".trash"])
        )
        
        try:
            for root, _, files in os.walk(vault_path):
                if self.interrupted:
                    break
                
                # è·³è¿‡ç‰¹æ®Šç›®å½•
                if any(x in root for x in ["templates", ".trash"]):
                    continue
                    
                for file in files:
                    if self.interrupted:
                        break
                        
                    if not file.endswith(".md"):
                        continue
                        
                    file_path = os.path.join(root, file)
                    rel_path = os.path.relpath(file_path, start=vault_path)
                    obsidian_link = rel_path.replace(".md", "")
                    
                    # è·³è¿‡å·²å¤„ç†æ–‡ä»¶
                    if obsidian_link in processed_links:
                        self.stats["skipped_files"] += 1
                        continue
                    
                    try:
                        # è¯»å–æ–‡ä»¶å†…å®¹
                        with open(file_path, "r", encoding="utf-8") as f:
                            raw_content = f.read()
                            
                        if not raw_content.strip():
                            continue
                            
                        # å¤„ç†å†…å®¹
                        content = self.process_content(raw_content)
                        summary, tokens = self.generate_summary(content)
                        
                        # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
                        self.stats["processed_files"] += 1
                        self.stats["total_tokens"] += tokens
                        
                        if summary:
                            # è¿½åŠ å†™å…¥ç»“æœ
                            with open(output_path, "a", encoding="utf-8") as f:
                                entry = f"- [[{obsidian_link}]]\n  {summary}\n\n"
                                f.write(entry)
                            
                            # æ›´æ–°å·²å¤„ç†è®°å½•
                            processed_links.add(obsidian_link)
                            
                        # æ˜¾ç¤ºå®æ—¶è¿›åº¦
                        self.print_progress()
                        
                    except Exception as e:
                        print(f"\nå¤„ç†æ–‡ä»¶å¤±è´¥ {file_path}: {str(e)}")
                        
            print(f"\n\nâœ… å¤„ç†å®Œæˆï¼ç»“æœå·²ä¿å­˜è‡³ï¼š{output_path}")
            
        finally:
            # æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
            total_time = time.time() - self.stats["start_time"]
            print(f"\nğŸ“Š æœ€ç»ˆç»Ÿè®¡ï¼š")
            print(f"- æ€»æ–‡ä»¶æ•°: {self.stats['total_files']}")
            print(f"- å·²å¤„ç†æ–‡ä»¶: {self.stats['processed_files']}")
            print(f"- è·³è¿‡æ–‡ä»¶: {self.stats['skipped_files']}")
            print(f"- æ€»Tokenç”¨é‡: {self.stats['total_tokens']}")
            print(f"- æ€»è€—æ—¶: {total_time:.1f}ç§’")
            if total_time > 0:
                print(f"- å¤„ç†é€Ÿåº¦: {self.stats['processed_files']/total_time:.1f} æ–‡ä»¶/ç§’")
                print(f"- Tokené€Ÿç‡: {self.stats['total_tokens']/total_time:.1f} token/ç§’")